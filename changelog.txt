Derek Organ - 11283394
Collective Intelligence - Project 2

CHANGE LOG -

To see all commits and changes you can also view my github repository for this project.
https://github.com/derekorgan/cf 

Note: This github repository is private until week 5 deadline has passed. 

------------------------------------------------------------------------------------
-- WEEK 5
-------------------------------------------------------------------------------------

v0.15 - Significance Weighting with Pearson Similarity 
----------------------------------------

Tested Pearson to see if significance weighting would improve it.  After an extensive test of many variations 
I found an improvement on pearson with no significance weighting but not better than the current Cosine numbers
RMSE: 1.0060005117816373     User Significance:1    Item Significance: 1  < no significance weighting
...
RMSE: 0.9921258089791603     User Significance:90    Item Significance: 60
RMSE: 0.9921178026898955     User Significance:90    Item Significance: 65
RMSE: 0.9921154630905042     User Significance:90    Item Significance: 70
RMSE: 0.9921154630905042     User Significance:90    Item Significance: 75
> RMSE: 0.9921154630905026     User Significance:90    Item Signifcance: 80
RMSE: 0.9921154630905039     User Significance:90    Item Significance: 85
RMSE: 0.9921154630905052     User Significance:90    Item Significance: 90
RMSE: 0.992115463090504     User Significance:90    Item Significance: 95
RMSE: 0.9921154630905036     User Significance:90    Item Significance: 100
...

The best score was with a MAX of 90 for user based and a MAX of 80 for Item.

Pearson without SW      1.0060005117816373
Pearson with SW			0.9921154630905026
Cosine 					0.9848579095001863			

So over all Cosine is still better.

v0.14 - Updated the reader to use the probe data as training data
----------------------------------------

This should help with the predictions on the r.test file because it has more training data to learn from.



------------------------------------------------------------------------------------
-- WEEK 4
-------------------------------------------------------------------------------------

v0.13 - Added significance weighting 
----------------------------------------
https://github.com/derekorgan/cf/commit/7294ca5257671419ec9b4531a85b56cb6e992184

I added significance weighting to the similarity metric for Cosine 

I created a double loop in the ExecuteHybrid to try the ranges of 1-5 and 5-75 in increments of 5 to 
test the best combination of max values for the significance. 

The best combination was no significance for user e.g. MAX = 1 and a max value of 3 for Item 

RMSE: 0.9850593918879242    max user sig :1       max item sig :1
RMSE: 0.9851617636433982    max user sig :1       max item sig :2
RMSE: 0.9848579095001863    max user sig :1       max item sig :3
RMSE: 0.9853052675535504    max user sig :1       max item sig :4
RMSE: 0.9852341878181543    max user sig :2       max item sig :1
RMSE: 0.985335793502781     max user sig :2       max item sig :2
...

In summary there really is little or no improvement using significance weighting on this data set with cosine.

RMSE: 0.9848579095001863
coverage: 99.88956377691883%


v0.12 - Code Re-factoring and Minimum neighbourhood size
----------------------------------------
https://github.com/derekorgan/cf/commit/ec5cfdab7dfdae24aaa522587cf74a31b2030d9c

I realized I need to change the way the code is organized. I'm currently combining the predictions from user based
and item based CF in the Evaluator.java.  It would be more appropriate to create a new class for the hybrid algorighm.

I created a new package alg.hybrid with ExecuteHybrid.java and HybridCF.java.  

I also tidied up the alg.ub and alg.ib packages so they can still work on there own. 

Lastly I tried one more time to change the neighbourhood minimum sizes in the Resnick function and found a small improvement
on the probe data. There is a very small drop off in coverage.

I found a minimum of 7 neighbours for users and a max of 53
with a minimum of 11 neighbours for items and a max of 22 had the lowest result.

RMSE: 0.9850593918879252
coverage: 99.88956377691883%


v0.11 - I added the global averages for user and items to the blending of predictions  
----------------------------------------
https://github.com/derekorgan/cf/commit/4c749e17f14fe4da5240a24ac4569668a630ce24

Next I tried adding a low weighted global average of user and items to the weighted calculation. 
by using the global average of the two I didn't find any improvement in the RMSE. 
I then tried some fixed values to see if tending to a overall average would help.
I found that 3.7 gave a slightly better over all RMSE of 0.9853882392739892


some code in the evaluator.java file..
			...
			// Get global average for this user and item.
			double globalU = userProfileMap.get(pair.getUserId()).getMeanValue();
			double globalI = itemProfileMap.get(pair.getItemId()).getMeanValue();	
			double global = (globalI + globalU) / 2;
			
			// weighted Average user and Item based prediction
			Double predictedRating = ((wU*upredictedRating) + (wI*ipredictedRating) + 3.7)/ (wU+wI+1); 
			...
			
As you can see in the final code I didn't actually use the Globals as they were not returning a better RMSE.
I may need to revisit this to factor in some weighting based on the number of neighbours with similarity threshold.

RMSE: 0.9853882392739892
Coverage: 100%


v0.10 - Weighed item and user based predictions average 
----------------------------------------
https://github.com/derekorgan/cf/commit/b7ad5127c4c5c8f322354d712045d1830782b674

I now wanted to test the weighted averages for user and item based predictions. 
I used a 10 point scale to see what returned the optimal point testing at each variation. 
Since Item based filtering on its own returns better values than user based i'm expecting more weight
for item based filtering.

User Weight:   0    Item Weight: 10    RMSE: 0.9890844621387777
User Weight:   1    Item Weight: 9     RMSE: 0.9877628943642665
User Weight:   2    Item Weight: 8     RMSE: 0.9870633832185663
User Weight:   3    Item Weight: 7     RMSE: 0.986987251320099
User Weight:   4    Item Weight: 6     RMSE: 0.9875346428431868
User Weight:   5    Item Weight: 5     RMSE: 0.9887045221561092
User Weight:   6    Item Weight: 4     RMSE: 0.9904946835889381
User Weight:   7    Item Weight: 3     RMSE: 0.9929017721171909
User Weight:   8    Item Weight: 2     RMSE: 0.9959213145115824
User Weight:   9    Item Weight: 1     RMSE: 0.9995477602861148
User Weight:   10    Item Weight: 0    RMSE: 1.0037745315841622

User Weight:   3    Item Weight: 7    Best RMSE: 0.986987251320099

I wrote a short bit of code to find the best result based on a fixed weighting. As expected the item
based algorithm is weighed more. 

Here is the code I used to generate this list in evaluator.java 
        ...
		int n = 10;
		Evaluator eval;
		double bestRMSE = 100.0;
		int bestwUser = 0;
		int bestwItem = 0;
		
		for (int i=0; i<n+1; i++)
		{
			int wU = i;
			int wI = n-i; 
			eval = new Evaluator(ubcf,ibcf, reader.getTestData(),wU ,wI);
			
			//eval.writeResults(outputFile);
			Double RMSE = eval.getRMSE();
			if(RMSE != null) System.out.println("User Weight:   "+ wU +"    Item Weight: "+ wI +"    RMSE: " + RMSE);
			
			if(RMSE < bestRMSE) 
			{
				bestRMSE = RMSE;
				bestwUser = wU;
				bestwItem = wI;
				
			}
			
			//double coverage = eval.getCoverage();
			//System.out.println("coverage: " + coverage + "%");
		}
		System.out.println("User Weight:   "+ bestwUser +"    Item Weight: "+ bestwItem +"    Best RMSE: " + bestRMSE);
		...

RMSE: 0.986987251320099
Coverage: 100%


v0.09 - Hybrid Item and User Based 
----------------------------------------
I decided to average my user based and item based scores to get a better approximation.

Code changes: 
In the Evaluator.java file I get predictions for user and item based and average them. 

RMSE: 0.9887045221561072
coverage: 100.0%

v0.08 - Testing Minimum neighbour size
----------------------------------------

I decided to experiment with a minimum neighbour size. In the current code it sets the minimum size to 0.  

For the User Based filtering I found the following results.

User Based Filtering
Cosine + Resnick  Max K = 53
k >         coverage         RSME
0			100%			 1.0037
4			99.96%		     1.0031
7 		    99.74%			 1.0036
10 			98.80%           1.0047
15			95.17%			 1.0061
20			89.09%			 1.0001
25			82.96%			 0.9980
30	        77.08%			 0.9989

There does seem to be a minor improvement but the coverage gets too low after a while.  
All users have a minimum of 4 neighbours as coverage is 100% up to this point. 

Item Based Filtering
Cosine + Resnick  Max K = 22
k >         coverage         RSME
0			100%			 0.9891		
7			99.98%			 0.9891
10			99.82%			 0.9892
15			95.98%			 0.9870	
20			84.76%			 0.9842		

All items have a minimum of 7 neighbours as coverage is 100% up to this point.

The main conclusion is setting a min size has a negligible effect on the RSME and I'm leaving it at 0 for now.

v0.07 - Updated K neighbours size for Item based filtering
----------------------------------------

The optimal neighbours for items is going to be different than for users.

10 - 0.9967420413981437
20 - 0.9893376268480041
22 - 0.9890844621387769
30 - 0.9906882336731407
40 - 0.9916727257768321

Some testing reveals 22 as the optimal number for the current setup on the probe data.

RSME: 0.9890844621387769
Coverage: 100.0%

v0.06 - Item based filtering
----------------------------------------
Changed code to test item based filtering instead of User based.

Item base seems to return better results than User based on the probe data.

Cosine + Resnick
RMSE: 0.992956721533153
coverage: 100.0%


------------------------------------------------------------------------------------
-- WEEK 2/3
-------------------------------------------------------------------------------------

v0.05 - Updated the Item Class to include other attributes such as year	
----------------------------------------
I've added year as an accessible attribute of item.

TODO: Add genre tags 



v0.04 - Added in Resnick Predictor Algorithm
----------------------------------------
Created a new predictor class using Resnick's algorigthm. 
By using a combination of Pearson's Simlarity and Resnick's predictor I found some improvement with the probe data.

Pearson + Resnick
RMSE: 1.0116696920563688
coverage: 99.79753359101785%

By using Cosine with Resnick I found it to have a better combinational effect on the probe data

Cosine + Resnick 
RMSE: 1.0037745315841637
coverage: 100.0%

------------------------------------------------------------------------------------
-- WEEK 1
-------------------------------------------------------------------------------------

v0.03 - Tested Pearson Similarity correlation - Feb 7. 2012
----------------------------------------

I changed the similarity algorithm to use Pearsons instead of Cosine which show an improvement with a very small coverage loss. 


RMSE: 1.100091240396238
coverage: 99.79753359101785%


v0.02 - Updated Fixed Neighbourhood size  - Feb 6, 2012
---------------------------------------

I tested changing the neighbourhood size to range between 1 and 100.  The following results were found


N size		RSME 
1 			1.4961451171826305
5			1.1831599539083058 
10 			1.134420381930053
20 			1.110594693291348
30			1.1073889468207587
40 			1.1058960051034536
50			1.1045085051581185  << best result
60			1.1053132181268333
70			1.1066042356564234
80			1.1069454038242852
90 			1.1071530413192758
100 		1.107469530198342

From the graph of information above we can see that a neighbourhood size of 50 gives the best results for our probe data with a fixed size. 

With bit more refinement I found 53 to be the optimal fix size for this set.

Result RSME: 1.1043132359396504 
coverage: 100%

v0.01 - Fixed Bugs - Feb 2nd, 2012
---------------------------------------

I found and fixed the two bugs. 

* Cosine Algorithm was incorrect
* Index in for loop for Mean Predictor referenced first item instead of incrementing.

Result RSME: 1.134420381930053
Coverage: 100%