Derek Organ - 11283394
Collective Intelligence - Project 2

CHANGE LOG

WEEK 4
-------------------------------------------------------------------------------------


v0.12 - Code Re-factoring and Minimum neighbourhood size
----------------------------------------

I realized I need to change the way the code is organized. I'm currently combining the predictions from user based
and item based CF in the Evaluator.java.  It would be more appropriate to create a new class for the hybrid algorighm.

I created a new package alg.hybrid with ExecuteHybrid.java and HybridCF.java.  

I also tidied up the alg.ub and alg.ib packages so they can still work on there own. 

Lastly tried one more time to change the neighbourhood minimum sizes in the Resnick function and found a small improvement
on the probe data. There is a very small drop off in coverage.

RMSE: 0.9850593918879252
coverage: 99.88956377691883%

v0.11 - I added the global averages for user and items to the blending of predictions  
----------------------------------------

Next I tried adding a low weighted global average of user and items to the weighted calculation. 
by using the global average of the two I didn't find any improvement in the RMSE. 
I then tried some fixed values to see if tending to a overall average would help.
I found that 3.7 gave a slightly better over all RMSE of 0.9853882392739892


some code in the evaluator.java file..
			...
			// Get global average for this user and item.
			double globalU = userProfileMap.get(pair.getUserId()).getMeanValue();
			double globalI = itemProfileMap.get(pair.getItemId()).getMeanValue();	
			double global = (globalI + globalU) / 2;
			
			// weighted Average user and Item based prediction
			Double predictedRating = ((wU*upredictedRating) + (wI*ipredictedRating) + 3.7)/ (wU+wI+1); 
			...
			
As you can see in the final code I didn't actually use the Globals as they were not returning a better RMSE.
I may need to revisit this to factor in some weighting based on the number of neighbours with similarity threshold.

RMSE: 0.9853882392739892
Coverage: 100%


v0.10 - Weighed item and user based predictions average 
----------------------------------------
I now wanted to test the weighted averages for user and item based predictions. 
I used a 10 point scale to see what returned the optimal point testing at each variation. 
Since Item based filtering on its own returns better values than user based i'm expecting more weight
for item based filtering.

User Weight:   0    Item Weight: 10    RMSE: 0.9890844621387777
User Weight:   1    Item Weight: 9     RMSE: 0.9877628943642665
User Weight:   2    Item Weight: 8     RMSE: 0.9870633832185663
User Weight:   3    Item Weight: 7     RMSE: 0.986987251320099
User Weight:   4    Item Weight: 6     RMSE: 0.9875346428431868
User Weight:   5    Item Weight: 5     RMSE: 0.9887045221561092
User Weight:   6    Item Weight: 4     RMSE: 0.9904946835889381
User Weight:   7    Item Weight: 3     RMSE: 0.9929017721171909
User Weight:   8    Item Weight: 2     RMSE: 0.9959213145115824
User Weight:   9    Item Weight: 1     RMSE: 0.9995477602861148
User Weight:   10    Item Weight: 0    RMSE: 1.0037745315841622

User Weight:   3    Item Weight: 7    Best RMSE: 0.986987251320099

I wrote a short bit of code to find the best result based on a fixed weighting. As expected the item
based algorithm is weighed more. 

Here is the code I used to generate this list in evaluator.java 
        ...
		int n = 10;
		Evaluator eval;
		double bestRMSE = 100.0;
		int bestwUser = 0;
		int bestwItem = 0;
		
		for (int i=0; i<n+1; i++)
		{
			int wU = i;
			int wI = n-i; 
			eval = new Evaluator(ubcf,ibcf, reader.getTestData(),wU ,wI);
			
			//eval.writeResults(outputFile);
			Double RMSE = eval.getRMSE();
			if(RMSE != null) System.out.println("User Weight:   "+ wU +"    Item Weight: "+ wI +"    RMSE: " + RMSE);
			
			if(RMSE < bestRMSE) 
			{
				bestRMSE = RMSE;
				bestwUser = wU;
				bestwItem = wI;
				
			}
			
			//double coverage = eval.getCoverage();
			//System.out.println("coverage: " + coverage + "%");
		}
		System.out.println("User Weight:   "+ bestwUser +"    Item Weight: "+ bestwItem +"    Best RMSE: " + bestRMSE);
		...

RMSE: 0.986987251320099
Coverage: 100%


v0.09 - Hybrid Item and User Based 
----------------------------------------
I decided to average my user based and item based scores to get a better approximation.

Code changes: 
In the Evaluator.java file I get predictions for user and item based and average them. 

RMSE: 0.9887045221561072
coverage: 100.0%

v0.08 - Testing Minimum neighbour size
----------------------------------------

I decided to experiment with a minimum neighbour size. In the current code it sets the minimum size to 0.  

For the User Based filtering I found the following results.

User Based Filtering
Cosine + Resnick  Max K = 53
k >         coverage         RSME
0			100%			 1.0037
4			99.96%		     1.0031
7 		    99.74%			 1.0036
10 			98.80%           1.0047
15			95.17%			 1.0061
20			89.09%			 1.0001
25			82.96%			 0.9980
30	        77.08%			 0.9989

There does seem to be a minor improvement but the coverage gets too low after a while.  
All users have a minimum of 4 neighbours as coverage is 100% up to this point. 

Item Based Filtering
Cosine + Resnick  Max K = 22
k >         coverage         RSME
0			100%			 0.9891		
7			99.98%			 0.9891
10			99.82%			 0.9892
15			95.98%			 0.9870	
20			84.76%			 0.9842		

All items have a minimum of 7 neighbours as coverage is 100% up to this point.

The main conclusion is setting a min size has a negligible effect on the RSME and I'm leaving it at 0 for now.

v0.07 - Updated K neighbours size for Item based filtering
----------------------------------------

The optimal neighbours for items is going to be different than for users.

10 - 0.9967420413981437
20 - 0.9893376268480041
22 - 0.9890844621387769
30 - 0.9906882336731407
40 - 0.9916727257768321

Some testing reveals 22 as the optimal number for the current setup on the probe data.

RSME: 0.9890844621387769
Coverage: 100.0%

v0.06 - Item based filtering
----------------------------------------
Changed code to test item based filtering instead of User based.

Item base seems to return better results than User based on the probe data.

Cosine + Resnick
RMSE: 0.992956721533153
coverage: 100.0%


WEEK 2/3
-------------------------------------------------------------------------------------
v0.05 - Updated the Item Class to include other attributes such as year	
----------------------------------------
I've added year as an accessible attribute of item.

TODO: Add genre tags 



v0.04 - Added in Resnick Predictor Algorithm
----------------------------------------
Created a new predictor class using Resnick's algorigthm. 
By using a combination of Pearson's Simlarity and Resnick's predictor I found some improvement with the probe data.

Pearson + Resnick
RMSE: 1.0116696920563688
coverage: 99.79753359101785%

By using Cosine with Resnick I found it to have a better combinational effect on the probe data

Cosine + Resnick 
RMSE: 1.0037745315841637
coverage: 100.0%

WEEK 1
-------------------------------------------------------------------------------------
v0.03 - Tested Pearson Similarity correlation - Feb 7. 2012
----------------------------------------

I changed the similarity algorithm to use Pearsons instead of Cosine which show an improvement with a very small coverage loss. 


RMSE: 1.100091240396238
coverage: 99.79753359101785%


v0.02 - Updated Fixed Neighbourhood size  - Feb 6, 2012
---------------------------------------

I tested changing the neighbourhood size to range between 1 and 100.  The following results were found


N size		RSME 
1 			1.4961451171826305
5			1.1831599539083058 
10 			1.134420381930053
20 			1.110594693291348
30			1.1073889468207587
40 			1.1058960051034536
50			1.1045085051581185  << best result
60			1.1053132181268333
70			1.1066042356564234
80			1.1069454038242852
90 			1.1071530413192758
100 		1.107469530198342

From the graph of information above we can see that a neighbourhood size of 50 gives the best results for our probe data with a fixed size. 

With bit more refinement I found 53 to be the optimal fix size for this set.

Result RSME: 1.1043132359396504 
coverage: 100%

v0.01 - Fixed Bugs - Feb 2nd, 2012
---------------------------------------

I found and fixed the two bugs. 

* Cosine Algorihtm was in correct
* Index in for loop for Mean Predictor referenced first item instead of incrementing.

Result RSME: 1.134420381930053
Coverage: 100%